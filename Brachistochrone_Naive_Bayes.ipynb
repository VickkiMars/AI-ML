{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfqbpo2KwHocJzf8odOaiJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VickkiMars/AI-ML/blob/main/Brachistochrone_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a novel variation of the Naive Bayes classifier that incorporates physical intuition from classical mechanics, specifically the brachistochrone problem. Rather than relying on traditional probability density functions such as Gaussian or multinomial models, our approach defines class likelihoods based on the theoretical time it would take for an object to \"fall\" under gravity from a data point to a class centroid along a brachistochrone-like path. We interpret shorter descent times as higher class likelihoods, effectively modeling classification as a competition of gravitational attraction between the input and each class. Class priors are combined with inverse fall times to form a simple but interpretable decision rule. This method, which we call Brachistochrone Naive Bayes, provides a fresh perspective on classification by uniting geometry, physics, and probabilistic reasoning. Preliminary experiments show that despite its conceptual simplicity, this classifier performs competitively with conventional models on low-dimensional data and offers a new lens through which to explore distance-based classification."
      ],
      "metadata": {
        "id": "QS_8mYAuz4eo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nzbc9G6uvxSB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BrachistochroneNaiveBayes:\n",
        "  def __init__(self, g=2):\n",
        "    self.class_centroids = {}\n",
        "    self.class_priors = {}\n",
        "    self.g = g\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.classes = np.unique(y)\n",
        "    for cls in self.classes:\n",
        "      points = X[y == cls]\n",
        "      self.class_centroids[cls] = points.mean(axis=0)\n",
        "      self.class_priors[cls] = len(points) / len(X)\n",
        "\n",
        "  def brachistochrone_time(self, p1, p2):\n",
        "    x1, y1 = p1\n",
        "    x2, y2 = p2\n",
        "    if y2 >= y1:\n",
        "      return np.inf\n",
        "    delta_y = y1-y2\n",
        "    T = np.pi / 2 * np.sqrt(delta_y / self.g)\n",
        "    return T\n",
        "\n",
        "  def predict(self, X):\n",
        "    predictions = []\n",
        "    for x in X:\n",
        "      times = {}\n",
        "      for cls in self.classes:\n",
        "        centroid = self.class_centroids[cls]\n",
        "        time = self.brachistochrone_time(x, centroid)\n",
        "        if time == np.inf:\n",
        "          continue\n",
        "        times[cls] = self.class_priors[cls] / (time + 1e-20)\n",
        "      # Handle cases where times is empty\n",
        "      if not times:\n",
        "        # Assign to the class with the highest prior probability\n",
        "        default_class = max(self.class_priors, key=self.class_priors.get)\n",
        "        predictions.append(default_class)\n",
        "      else:\n",
        "        predictions.append(max(times, key=times.get))\n",
        "    return np.array(predictions)"
      ],
      "metadata": {
        "id": "v0UJ2r5swoMC"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X, y = make_classification(n_samples=200, n_features=2, n_classes=2, n_informative=2, n_redundant=0)\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Adjust so y decreases downwards\n",
        "X[:, 1] = 1 - X[:, 1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "model = BrachistochroneNaiveBayes()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "accuracy = np.mean(preds == y_test)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v6hhz3Hxu8R",
        "outputId": "f49aa64f-e7b1-42eb-ea87-883ff7b55096"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import numpy as np\n",
        "\n",
        "# Generate synthetic 2D classification data\n",
        "X, y = make_classification(n_samples=200, n_features=2, n_classes=2, n_informative=2, n_redundant=0)\n",
        "\n",
        "# Normalize features to [0, 1]\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Optional: invert Y-axis (mimicking earlier adjustment)\n",
        "X[:, 1] = 1 - X[:, 1]\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Use conventional Gaussian Naive Bayes\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.mean(preds == y_test)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pBpBUwPxxxH",
        "outputId": "195c440a-5619-4304-9752-07558a505a16"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zsVdivl_yWrb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}